{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from nltk import text\n",
    "from nltk.tokenize import TweetTokenizer, WordPunctTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Embedding, Dropout, BatchNormalization, Conv1D, MaxPool1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing import sequence\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>directed_at</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X                                         tweet_text directed_at  \\\n",
       "0  1  .@wesley83 I have a 3G iPhone. After 3 hrs twe...      iPhone   \n",
       "1  3  @swonderlin Can not wait for #iPad 2 also. The...        iPad   \n",
       "2  5  @sxtxstate great stuff on Fri #SXSW: Marissa M...      Google   \n",
       "3  6  @teachntech00 New iPad Apps For #SpeechTherapy...         NaN   \n",
       "4  7                                                NaN         NaN   \n",
       "\n",
       "  tweet_sentiment  \n",
       "0        negative  \n",
       "1        positive  \n",
       "2        positive  \n",
       "3         neutral  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8936, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "negative_tweets = pd.read_csv('negative_tweet_supplement.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>@apple Contact sync between Yosemite and iOS8 ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>WARNING IF YOU BUY AN IPHONE 5S UNLOCKED FROM ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>@Apple, For the love of GAWD, CENTER the '1'on...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>i get the storage almost full notification lit...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X                                         tweet_text tweet_sentiment\n",
       "0  11  WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...        negative\n",
       "1  15  @apple Contact sync between Yosemite and iOS8 ...        negative\n",
       "2  17  WARNING IF YOU BUY AN IPHONE 5S UNLOCKED FROM ...        negative\n",
       "3  24  @Apple, For the love of GAWD, CENTER the '1'on...        negative\n",
       "4  25  i get the storage almost full notification lit...        negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1219, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11567, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_tweets = pd.read_csv('airline_tweets.csv')\n",
    "airline_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text tweet_sentiment\n",
       "0  @VirginAmerica plus you've added commercials t...        positive\n",
       "1  @VirginAmerica it's really aggressive to blast...        negative\n",
       "2  @VirginAmerica and it's a really big bad thing...        negative\n",
       "3  @VirginAmerica seriously would pay $30 a fligh...        negative\n",
       "4  @VirginAmerica yes, nearly every time I fly VX...        positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10262, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debate_tweets = pd.read_csv('gop_debate_tweets.csv')\n",
    "debate_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text tweet_sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         neutral\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...        positive\n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         neutral\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...        positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...        positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debate_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tweets = tweets.drop('directed_at', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tweets = tweets.append(negative_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10155, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tweets = all_tweets.drop('X', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10155, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tweets = all_tweets.append(airline_tweets)\n",
    "all_tweets = all_tweets.append(debate_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31984, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def ingest(all_tweets):\n",
    "    all_tweets = all_tweets[all_tweets['tweet_text'].isnull() == False]\n",
    "    all_tweets = all_tweets[all_tweets['tweet_sentiment'].isnull() == False]\n",
    "    all_tweets.reset_index(inplace=True)\n",
    "    return all_tweets\n",
    "\n",
    "all_tweets = ingest(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "punctuations = list(punctuation)\n",
    "\n",
    "def tokenize(tweet):\n",
    "    try:\n",
    "        tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True)\n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        tokens = filter(lambda t: t not in punctuations, tokens)\n",
    "        tokens = filter(lambda t: not t.startswith('#'), tokens)\n",
    "        tokens = filter(lambda t: not t.startswith('http'), tokens)\n",
    "        return list(tokens)\n",
    "    except:\n",
    "        return 'NC'\n",
    "\n",
    "def postprocess(data):\n",
    "    data['tokens'] = list(map(lambda x: tokenize(x), data['tweet_text']))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tweets = postprocess(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[i, have, a, 3g, iphone, after, 3, hrs, tweeti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[can, not, wait, for, 2, also, they, should, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[great, stuff, on, fri, marissa, mayer, google...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[new, ipad, apps, for, and, communication, are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[is, just, starting, is, around, the, corner, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         tweet_text tweet_sentiment  \\\n",
       "0      0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...        negative   \n",
       "1      1  @swonderlin Can not wait for #iPad 2 also. The...        positive   \n",
       "2      2  @sxtxstate great stuff on Fri #SXSW: Marissa M...        positive   \n",
       "3      3  @teachntech00 New iPad Apps For #SpeechTherapy...         neutral   \n",
       "4      5  #SXSW is just starting, #CTIA is around the co...        positive   \n",
       "\n",
       "                                              tokens  \n",
       "0  [i, have, a, 3g, iphone, after, 3, hrs, tweeti...  \n",
       "1  [can, not, wait, for, 2, also, they, should, s...  \n",
       "2  [great, stuff, on, fri, marissa, mayer, google...  \n",
       "3  [new, ipad, apps, for, and, communication, are...  \n",
       "4  [is, just, starting, is, around, the, corner, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tokens = [item for sublist in all_tweets.tokens.values for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490727"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22546"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t = text.Text(set(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t.index('hostage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "token_dict = {k: v for v, k in enumerate(set(all_tokens))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22546"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = FreqDist(all_tokens)\n",
    "len(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 16134),\n",
       " ('to', 13972),\n",
       " ('a', 8821),\n",
       " ('rt', 7918),\n",
       " ('i', 7620),\n",
       " ('for', 7265),\n",
       " ('and', 6608),\n",
       " ('is', 6251),\n",
       " ('of', 5884),\n",
       " ('on', 5860),\n",
       " ('you', 5734),\n",
       " ('in', 5690),\n",
       " ('at', 5020),\n",
       " ('my', 4341),\n",
       " ('link', 4320),\n",
       " ('it', 3436),\n",
       " ('flight', 3085),\n",
       " ('that', 2815),\n",
       " ('with', 2796),\n",
       " ('this', 2748)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2806,\n",
       " 18537,\n",
       " 6855,\n",
       " 15532,\n",
       " 22145,\n",
       " 4917,\n",
       " 1287,\n",
       " 22115,\n",
       " 1427,\n",
       " 6436,\n",
       " 6691,\n",
       " 7600,\n",
       " 8261,\n",
       " 2806,\n",
       " 20873,\n",
       " 5505,\n",
       " 169,\n",
       " 1452,\n",
       " 11903,\n",
       " 6436]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: token_dict.get(x), all_tweets.tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(token_dict.keys())[list(token_dict.values()).index(2806)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2806,\n",
       " 18537,\n",
       " 6855,\n",
       " 15532,\n",
       " 22145,\n",
       " 4917,\n",
       " 1287,\n",
       " 22115,\n",
       " 1427,\n",
       " 6436,\n",
       " 6691,\n",
       " 7600,\n",
       " 8261,\n",
       " 2806,\n",
       " 20873,\n",
       " 5505,\n",
       " 169,\n",
       " 1452,\n",
       " 11903,\n",
       " 6436]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_indices(tokens):\n",
    "    idxs = []\n",
    "    for t in tokens:\n",
    "        idxs.append(token_dict.get(t))\n",
    "    return idxs\n",
    "\n",
    "get_word_indices(all_tweets.tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tweets['indexed_text'] = list(map(lambda x: get_word_indices(x), all_tweets.tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>indexed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[i, have, a, 3g, iphone, after, 3, hrs, tweeti...</td>\n",
       "      <td>[2806, 18537, 6855, 15532, 22145, 4917, 1287, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[can, not, wait, for, 2, also, they, should, s...</td>\n",
       "      <td>[3720, 6192, 7632, 17459, 21173, 21235, 11543,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[great, stuff, on, fri, marissa, mayer, google...</td>\n",
       "      <td>[9490, 8855, 2358, 6083, 4351, 2227, 4547, 207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[new, ipad, apps, for, and, communication, are...</td>\n",
       "      <td>[7394, 15164, 6661, 17459, 19353, 19467, 1435,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[is, just, starting, is, around, the, corner, ...</td>\n",
       "      <td>[12997, 5224, 10116, 12997, 11240, 21619, 5707...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         tweet_text tweet_sentiment  \\\n",
       "0      0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...        negative   \n",
       "1      1  @swonderlin Can not wait for #iPad 2 also. The...        positive   \n",
       "2      2  @sxtxstate great stuff on Fri #SXSW: Marissa M...        positive   \n",
       "3      3  @teachntech00 New iPad Apps For #SpeechTherapy...         neutral   \n",
       "4      5  #SXSW is just starting, #CTIA is around the co...        positive   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [i, have, a, 3g, iphone, after, 3, hrs, tweeti...   \n",
       "1  [can, not, wait, for, 2, also, they, should, s...   \n",
       "2  [great, stuff, on, fri, marissa, mayer, google...   \n",
       "3  [new, ipad, apps, for, and, communication, are...   \n",
       "4  [is, just, starting, is, around, the, corner, ...   \n",
       "\n",
       "                                        indexed_text  \n",
       "0  [2806, 18537, 6855, 15532, 22145, 4917, 1287, ...  \n",
       "1  [3720, 6192, 7632, 17459, 21173, 21235, 11543,...  \n",
       "2  [9490, 8855, 2358, 6083, 4351, 2227, 4547, 207...  \n",
       "3  [7394, 15164, 6661, 17459, 19353, 19467, 1435,...  \n",
       "4  [12997, 5224, 10116, 12997, 11240, 21619, 5707...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tweets.drop(['index', 'tweet_text', 'tokens'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(all_tweets.indexed_text), \n",
    "                                                    np.asarray(all_tweets.tweet_sentiment),\n",
    "                                                    test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28784,), (28784,), (3199,), (3199,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19561,\n",
       " 6691,\n",
       " 11171,\n",
       " 3397,\n",
       " 10388,\n",
       " 1285,\n",
       " 2806,\n",
       " 22425,\n",
       " 6855,\n",
       " 21440,\n",
       " 2358,\n",
       " 21619,\n",
       " 2122,\n",
       " 18322,\n",
       " 20656,\n",
       " 16860]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=120, value=0)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=120, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(['negative', 'neutral', 'positive'])\n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28784, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create simple models\n",
    "### Single hidden layer NN\n",
    "The simplest model that tends to give reasonable results is a single hidden layer net. So let's try that. Note that we can't expect to get any useful results by feeding word ids directly into a neural net - so instead we use an embedding to replace them with a vector of 32 (initially random) floats for each word in the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(X_train.shape[0], 32, input_length=120, embeddings_regularizer=l2(0.002)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, kernel_regularizer=l2(0.001), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.65))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_56 (Embedding)     (None, 120, 32)           921088    \n",
      "_________________________________________________________________\n",
      "dropout_155 (Dropout)        (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 120, 32)           128       \n",
      "_________________________________________________________________\n",
      "flatten_56 (Flatten)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 200)               768200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 1,690,819\n",
      "Trainable params: 1,690,355\n",
      "Non-trainable params: 464\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25905 samples, validate on 2879 samples\n",
      "Epoch 1/10\n",
      "Epoch 00000: val_loss improved from inf to 1.45085, saving model to tweet_sentiment_simple\n",
      "18s - loss: 1.8450 - acc: 0.5126 - val_loss: 1.4508 - val_acc: 0.6110\n",
      "Epoch 2/10\n",
      "Epoch 00001: val_loss improved from 1.45085 to 1.16064, saving model to tweet_sentiment_simple\n",
      "12s - loss: 1.2465 - acc: 0.6627 - val_loss: 1.1606 - val_acc: 0.6818\n",
      "Epoch 3/10\n",
      "Epoch 00002: val_loss improved from 1.16064 to 1.08555, saving model to tweet_sentiment_simple\n",
      "12s - loss: 1.0968 - acc: 0.7167 - val_loss: 1.0855 - val_acc: 0.7065\n",
      "Epoch 4/10\n",
      "Epoch 00003: val_loss improved from 1.08555 to 1.06279, saving model to tweet_sentiment_simple\n",
      "12s - loss: 1.0089 - acc: 0.7454 - val_loss: 1.0628 - val_acc: 0.7068\n",
      "Epoch 5/10\n",
      "Epoch 00004: val_loss did not improve\n",
      "12s - loss: 0.9619 - acc: 0.7616 - val_loss: 1.0876 - val_acc: 0.6989\n",
      "Epoch 6/10\n",
      "Epoch 00005: val_loss did not improve\n",
      "12s - loss: 0.9337 - acc: 0.7746 - val_loss: 1.0712 - val_acc: 0.7093\n",
      "Epoch 7/10\n",
      "Epoch 00006: val_loss did not improve\n",
      "12s - loss: 0.9225 - acc: 0.7837 - val_loss: 1.1218 - val_acc: 0.7002\n",
      "Model took 96.23 seconds to train\n",
      "3199/3199 [==============================] - 2s     \n",
      "[1.106260677656929, 0.69209127831958395]\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint = ModelCheckpoint(filepath='tweet_sentiment_simple', verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, validation_split=0.1, epochs=10, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))\n",
    "\n",
    "# Re-instantiate model to the best model saved\n",
    "model = load_model('tweet_sentiment_simple')\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=64)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single conv layer with max pooling\n",
    "A CNN is likely to work better, since it's designed to take advantage of ordered data. We'll need to use a 1D CNN, since a sequence of words is 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(X_train.shape[0], 32, input_length=120, embeddings_regularizer=l2(0.003)))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Conv1D(40, 5, padding='same', activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(MaxPool1D())\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(225, kernel_regularizer=l2(0.002), activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.7))\n",
    "model2.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_45 (Embedding)     (None, 120, 32)           921088    \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 120, 40)           6440      \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 120, 40)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 60, 40)            0         \n",
      "_________________________________________________________________\n",
      "flatten_45 (Flatten)         (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 225)               540225    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 225)               900       \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 225)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 3)                 678       \n",
      "=================================================================\n",
      "Total params: 1,469,331\n",
      "Trainable params: 1,468,881\n",
      "Non-trainable params: 450\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25905 samples, validate on 2879 samples\n",
      "Epoch 1/30\n",
      "Epoch 00000: val_loss improved from inf to 1.61902, saving model to tweet_sentiment_cnn\n",
      "18s - loss: 2.4082 - acc: 0.4544 - val_loss: 1.6190 - val_acc: 0.4658\n",
      "Epoch 2/30\n",
      "Epoch 00001: val_loss improved from 1.61902 to 1.15735, saving model to tweet_sentiment_cnn\n",
      "14s - loss: 1.3105 - acc: 0.5572 - val_loss: 1.1573 - val_acc: 0.5662\n",
      "Epoch 3/30\n",
      "Epoch 00002: val_loss improved from 1.15735 to 1.05563, saving model to tweet_sentiment_cnn\n",
      "14s - loss: 1.0284 - acc: 0.6023 - val_loss: 1.0556 - val_acc: 0.5384\n",
      "Epoch 4/30\n",
      "Epoch 00003: val_loss improved from 1.05563 to 0.92162, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.9268 - acc: 0.6233 - val_loss: 0.9216 - val_acc: 0.6356\n",
      "Epoch 5/30\n",
      "Epoch 00004: val_loss improved from 0.92162 to 0.85454, saving model to tweet_sentiment_cnn\n",
      "14s - loss: 0.8704 - acc: 0.6349 - val_loss: 0.8545 - val_acc: 0.6398\n",
      "Epoch 6/30\n",
      "Epoch 00005: val_loss improved from 0.85454 to 0.84533, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.8444 - acc: 0.6384 - val_loss: 0.8453 - val_acc: 0.6447\n",
      "Epoch 7/30\n",
      "Epoch 00006: val_loss improved from 0.84533 to 0.81392, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.8272 - acc: 0.6404 - val_loss: 0.8139 - val_acc: 0.6474\n",
      "Epoch 8/30\n",
      "Epoch 00007: val_loss improved from 0.81392 to 0.80851, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.8109 - acc: 0.6477 - val_loss: 0.8085 - val_acc: 0.6502\n",
      "Epoch 9/30\n",
      "Epoch 00008: val_loss improved from 0.80851 to 0.78144, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.7957 - acc: 0.6591 - val_loss: 0.7814 - val_acc: 0.6652\n",
      "Epoch 10/30\n",
      "Epoch 00009: val_loss improved from 0.78144 to 0.76025, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.7771 - acc: 0.6716 - val_loss: 0.7603 - val_acc: 0.6836\n",
      "Epoch 11/30\n",
      "Epoch 00010: val_loss improved from 0.76025 to 0.75136, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.7665 - acc: 0.6867 - val_loss: 0.7514 - val_acc: 0.6968\n",
      "Epoch 12/30\n",
      "Epoch 00011: val_loss improved from 0.75136 to 0.74056, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.7509 - acc: 0.6930 - val_loss: 0.7406 - val_acc: 0.6950\n",
      "Epoch 13/30\n",
      "Epoch 00012: val_loss improved from 0.74056 to 0.73603, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.7443 - acc: 0.7020 - val_loss: 0.7360 - val_acc: 0.6923\n",
      "Epoch 14/30\n",
      "Epoch 00013: val_loss improved from 0.73603 to 0.73132, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.7299 - acc: 0.7042 - val_loss: 0.7313 - val_acc: 0.7020\n",
      "Epoch 15/30\n",
      "Epoch 00014: val_loss improved from 0.73132 to 0.72029, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.7254 - acc: 0.7097 - val_loss: 0.7203 - val_acc: 0.7086\n",
      "Epoch 16/30\n",
      "Epoch 00015: val_loss improved from 0.72029 to 0.71720, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.7177 - acc: 0.7143 - val_loss: 0.7172 - val_acc: 0.7079\n",
      "Epoch 17/30\n",
      "Epoch 00016: val_loss improved from 0.71720 to 0.71117, saving model to tweet_sentiment_cnn\n",
      "15s - loss: 0.7161 - acc: 0.7139 - val_loss: 0.7112 - val_acc: 0.7159\n",
      "Epoch 18/30\n",
      "Epoch 00017: val_loss did not improve\n",
      "15s - loss: 0.7129 - acc: 0.7177 - val_loss: 0.7148 - val_acc: 0.7103\n",
      "Epoch 19/30\n",
      "Epoch 00018: val_loss did not improve\n",
      "14s - loss: 0.7071 - acc: 0.7207 - val_loss: 0.7202 - val_acc: 0.7114\n",
      "Epoch 20/30\n",
      "Epoch 00019: val_loss did not improve\n",
      "15s - loss: 0.7038 - acc: 0.7207 - val_loss: 0.7130 - val_acc: 0.7093\n",
      "Model took 308.09 seconds to train\n",
      "2912/3199 [==========================>...] - ETA: 0s[0.73741567913686235, 0.70365739274896955]\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint = ModelCheckpoint(filepath='tweet_sentiment_cnn', verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model2.fit(X_train, y_train, batch_size=64, validation_split=0.1, epochs=30, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))\n",
    "\n",
    "# Re-instantiate model to the best model saved\n",
    "model2 = load_model('tweet_sentiment_cnn')\n",
    "\n",
    "y_pred = model2.predict(X_test, batch_size=64)\n",
    "score = model2.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
