{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Embedding, Dropout, BatchNormalization, Conv1D, MaxPool1D, SpatialDropout1D, LSTM\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing import sequence\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>directed_at</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X                                         tweet_text directed_at  \\\n",
       "0  1  .@wesley83 I have a 3G iPhone. After 3 hrs twe...      iPhone   \n",
       "1  3  @swonderlin Can not wait for #iPad 2 also. The...        iPad   \n",
       "2  5  @sxtxstate great stuff on Fri #SXSW: Marissa M...      Google   \n",
       "3  6  @teachntech00 New iPad Apps For #SpeechTherapy...         NaN   \n",
       "4  7                                                NaN         NaN   \n",
       "\n",
       "  tweet_sentiment  \n",
       "0        negative  \n",
       "1        positive  \n",
       "2        positive  \n",
       "3         neutral  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8936, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_tweets = pd.read_csv('negative_tweet_supplement.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>@apple Contact sync between Yosemite and iOS8 ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>WARNING IF YOU BUY AN IPHONE 5S UNLOCKED FROM ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>@Apple, For the love of GAWD, CENTER the '1'on...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>i get the storage almost full notification lit...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X                                         tweet_text tweet_sentiment\n",
       "0  11  WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...        negative\n",
       "1  15  @apple Contact sync between Yosemite and iOS8 ...        negative\n",
       "2  17  WARNING IF YOU BUY AN IPHONE 5S UNLOCKED FROM ...        negative\n",
       "3  24  @Apple, For the love of GAWD, CENTER the '1'on...        negative\n",
       "4  25  i get the storage almost full notification lit...        negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1219, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11567, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_tweets = pd.read_csv('airline_tweets.csv')\n",
    "airline_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text tweet_sentiment\n",
       "0  @VirginAmerica plus you've added commercials t...        positive\n",
       "1  @VirginAmerica it's really aggressive to blast...        negative\n",
       "2  @VirginAmerica and it's a really big bad thing...        negative\n",
       "3  @VirginAmerica seriously would pay $30 a fligh...        negative\n",
       "4  @VirginAmerica yes, nearly every time I fly VX...        positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10262, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debate_tweets = pd.read_csv('gop_debate_tweets.csv')\n",
    "debate_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text tweet_sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         neutral\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...        positive\n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         neutral\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...        positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...        positive"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debate_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = tweets.drop('directed_at', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets = tweets.append(negative_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10155, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets = all_tweets.drop('X', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10155, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets = all_tweets.append(airline_tweets)\n",
    "all_tweets = all_tweets.append(debate_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31984, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ingest(all_tweets):\n",
    "    all_tweets = all_tweets[all_tweets['tweet_text'].isnull() == False]\n",
    "    all_tweets = all_tweets[all_tweets['tweet_sentiment'].isnull() == False]\n",
    "    return all_tweets\n",
    "\n",
    "all_tweets = ingest(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31983, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15138, 2), (10397, 2), (6448, 2))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets[all_tweets['tweet_sentiment'] == 'negative'].shape, all_tweets[all_tweets['tweet_sentiment'] == 'neutral'].shape, all_tweets[all_tweets['tweet_sentiment'] == 'positive'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_tweets['tweet_text'] = all_tweets['tweet_text'].apply(lambda x: x.lower())\n",
    "#all_tweets['tweet_text'] = all_tweets['tweet_text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','', x)))\n",
    "\n",
    "max_features = 5000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(all_tweets['tweet_text'].values)\n",
    "X = tokenizer.texts_to_sequences(all_tweets['tweet_text'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31983, 50)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    6,   34,    4, 1721,\n",
       "         53,  103,  134,  382,  963,   16, 2639,   84,   23,   32, 1290,\n",
       "          6,   88,    2,  666,   16,    3], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(all_tweets['tweet_sentiment']).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28784, 50), (28784, 3), (3199, 50), (3199, 3))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0, 1542,   35,  173, 2306, 3002, 1570,   45,   31, 3002,   20,\n",
       "        109,    8,  808,  178,    3,   22], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three models: Simple Neural Network, CNN, and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Single hidden layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embed_dim = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1]))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint = ModelCheckpoint(filepath='tweet_sentiment_simple', verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, validation_split=0.1, epochs=30, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))\n",
    "\n",
    "# Re-instantiate model to the best model saved\n",
    "model = load_model('tweet_sentiment_simple')\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=64)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Single conv layer with max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1]))\n",
    "model2.add(SpatialDropout1D(0.3))\n",
    "model2.add(Dropout(0.6))\n",
    "model2.add(Conv1D(32, 5, padding='same', activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(MaxPool1D(5))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(100, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.7))\n",
    "model2.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint = ModelCheckpoint(filepath='tweet_sentiment_cnn', verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model2.fit(X_train, y_train, batch_size=64, validation_split=0.1, epochs=30, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))\n",
    "\n",
    "# Re-instantiate model to the best model saved\n",
    "model2 = load_model('tweet_sentiment_cnn')\n",
    "\n",
    "y_pred = model2.predict(X_test, batch_size=64)\n",
    "score = model2.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Multi-layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embed_dim = 32\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1], embeddings_regularizer=l2(0.0001)))\n",
    "model3.add(SpatialDropout1D(0.2))\n",
    "model3.add(Dropout(0.6))\n",
    "\n",
    "model3.add(Conv1D(128, 5, activation='relu'))\n",
    "model3.add(Dropout(0.6))\n",
    "model3.add(MaxPool1D())\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(256, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "model3.add(Dropout(0.7))\n",
    "model3.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_50 (Embedding)     (None, 50, 32)            160000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_48 (Spatia (None, 50, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_173 (Dropout)        (None, 50, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 46, 128)           20608     \n",
      "_________________________________________________________________\n",
      "dropout_174 (Dropout)        (None, 46, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling (None, 23, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 2944)              0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 256)               753920    \n",
      "_________________________________________________________________\n",
      "dropout_175 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 935,299\n",
      "Trainable params: 935,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model3.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001, decay=1e-7), metrics=['accuracy'])\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25905 samples, validate on 2879 samples\n",
      "Epoch 1/30\n",
      "Epoch 00000: val_loss improved from inf to 0.69594, saving model to tweet_sentiment_multicnn\n",
      "13s - loss: 0.6493 - acc: 0.7389 - val_loss: 0.6959 - val_acc: 0.7131\n",
      "Epoch 2/30\n",
      "Epoch 00001: val_loss did not improve\n",
      "11s - loss: 0.6518 - acc: 0.7381 - val_loss: 0.6984 - val_acc: 0.7127\n",
      "Epoch 3/30\n",
      "Epoch 00002: val_loss improved from 0.69594 to 0.69433, saving model to tweet_sentiment_multicnn\n",
      "11s - loss: 0.6477 - acc: 0.7412 - val_loss: 0.6943 - val_acc: 0.7110\n",
      "Epoch 4/30\n",
      "Epoch 00003: val_loss did not improve\n",
      "11s - loss: 0.6460 - acc: 0.7450 - val_loss: 0.6980 - val_acc: 0.7110\n",
      "Epoch 5/30\n",
      "Epoch 00004: val_loss did not improve\n",
      "11s - loss: 0.6476 - acc: 0.7406 - val_loss: 0.6985 - val_acc: 0.7152\n",
      "Epoch 6/30\n",
      "Epoch 00005: val_loss did not improve\n",
      "11s - loss: 0.6433 - acc: 0.7449 - val_loss: 0.6965 - val_acc: 0.7166\n",
      "Model took 72.11 seconds to train\n",
      "3168/3199 [============================>.] - ETA: 0s[0.67954240338285854, 0.71553610514461641]\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint = ModelCheckpoint(filepath='tweet_sentiment_multicnn', verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model3.fit(X_train, y_train, batch_size=64, validation_split=0.1, epochs=30, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))\n",
    "\n",
    "# Re-instantiate model to the best model saved\n",
    "model3 = load_model('tweet_sentiment_multicnn')\n",
    "\n",
    "y_pred = model3.predict(X_test, batch_size=64)\n",
    "score = model3.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 50, 64)            320000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 50, 64)            256       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 75)                7275      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 228       \n",
      "=================================================================\n",
      "Total params: 389,583\n",
      "Trainable params: 389,455\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 64\n",
    "lstm_out = 96\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(max_features, embed_dim, input_length = X.shape[1]))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(LSTM(lstm_out, dropout=0.5, recurrent_dropout=0.3, activation='relu'))\n",
    "model3.add(Dense(75, activation='relu'))\n",
    "model3.add(Dropout(0.7))\n",
    "model3.add(Dense(3, activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25905 samples, validate on 2879 samples\n",
      "Epoch 1/30\n",
      "Epoch 00000: val_loss improved from inf to 1.00594, saving model to tweet_sentiment_lstm\n",
      "61s - loss: 0.9313 - acc: 0.5772 - val_loss: 1.0059 - val_acc: 0.6235\n",
      "Epoch 2/30\n",
      "Epoch 00001: val_loss improved from 1.00594 to 0.74491, saving model to tweet_sentiment_lstm\n",
      "58s - loss: 0.7781 - acc: 0.6480 - val_loss: 0.7449 - val_acc: 0.6447\n",
      "Epoch 3/30\n",
      "Epoch 00002: val_loss improved from 0.74491 to 0.71361, saving model to tweet_sentiment_lstm\n",
      "58s - loss: 0.7277 - acc: 0.6707 - val_loss: 0.7136 - val_acc: 0.6843\n",
      "Epoch 4/30\n",
      "Epoch 00003: val_loss improved from 0.71361 to 0.70809, saving model to tweet_sentiment_lstm\n",
      "56s - loss: 0.6924 - acc: 0.6925 - val_loss: 0.7081 - val_acc: 0.6933\n",
      "Epoch 5/30\n",
      "Epoch 00004: val_loss improved from 0.70809 to 0.69929, saving model to tweet_sentiment_lstm\n",
      "54s - loss: 0.6625 - acc: 0.7114 - val_loss: 0.6993 - val_acc: 0.7051\n",
      "Epoch 6/30\n",
      "Epoch 00005: val_loss improved from 0.69929 to 0.68780, saving model to tweet_sentiment_lstm\n",
      "54s - loss: 0.6400 - acc: 0.7253 - val_loss: 0.6878 - val_acc: 0.7096\n",
      "Epoch 7/30\n",
      "Epoch 00006: val_loss did not improve\n",
      "54s - loss: 0.6120 - acc: 0.7406 - val_loss: 0.6892 - val_acc: 0.7117\n",
      "Epoch 8/30\n",
      "Epoch 00007: val_loss did not improve\n",
      "55s - loss: 0.5903 - acc: 0.7539 - val_loss: 0.6925 - val_acc: 0.7093\n",
      "Epoch 9/30\n",
      "Epoch 00008: val_loss did not improve\n",
      "55s - loss: 0.5760 - acc: 0.7611 - val_loss: 0.7066 - val_acc: 0.7089\n",
      "Model took 511.69 seconds to train\n",
      "3168/3199 [============================>.] - ETA: 0s[0.66952721664181869, 0.71084713954484324]\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint = ModelCheckpoint(filepath='tweet_sentiment_lstm', verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model3.fit(X_train, y_train, batch_size=64, validation_split=0.1, epochs=30, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))\n",
    "\n",
    "# Re-instantiate model to the best model saved\n",
    "model3 = load_model('tweet_sentiment_lstm')\n",
    "\n",
    "y_pred = model3.predict(X_test, batch_size=64)\n",
    "score = model3.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pre-trained Model (GloVe-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join('glove.twitter.27B', 'glove.twitter.27B.25d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34043 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_dim = 32\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embed_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
