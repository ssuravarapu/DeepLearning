{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Embedding, Dropout, BatchNormalization, Conv1D, MaxPool1D, SpatialDropout1D, LSTM\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing import sequence\n",
    "from keras.regularizers import l2\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>directed_at</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X                                         tweet_text directed_at  \\\n",
       "0  1  .@wesley83 I have a 3G iPhone. After 3 hrs twe...      iPhone   \n",
       "1  3  @swonderlin Can not wait for #iPad 2 also. The...        iPad   \n",
       "2  5  @sxtxstate great stuff on Fri #SXSW: Marissa M...      Google   \n",
       "3  6  @teachntech00 New iPad Apps For #SpeechTherapy...         NaN   \n",
       "4  7                                                NaN         NaN   \n",
       "\n",
       "  tweet_sentiment  \n",
       "0        negative  \n",
       "1        positive  \n",
       "2        positive  \n",
       "3         neutral  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8936, 4)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "negative_tweets = pd.read_csv('negative_tweet_supplement.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>@apple Contact sync between Yosemite and iOS8 ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>WARNING IF YOU BUY AN IPHONE 5S UNLOCKED FROM ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>@Apple, For the love of GAWD, CENTER the '1'on...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>i get the storage almost full notification lit...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X                                         tweet_text tweet_sentiment\n",
       "0  11  WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...        negative\n",
       "1  15  @apple Contact sync between Yosemite and iOS8 ...        negative\n",
       "2  17  WARNING IF YOU BUY AN IPHONE 5S UNLOCKED FROM ...        negative\n",
       "3  24  @Apple, For the love of GAWD, CENTER the '1'on...        negative\n",
       "4  25  i get the storage almost full notification lit...        negative"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1219, 3)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11567, 2)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_tweets = pd.read_csv('airline_tweets.csv')\n",
    "airline_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text tweet_sentiment\n",
       "0  @VirginAmerica plus you've added commercials t...        positive\n",
       "1  @VirginAmerica it's really aggressive to blast...        negative\n",
       "2  @VirginAmerica and it's a really big bad thing...        negative\n",
       "3  @VirginAmerica seriously would pay $30 a fligh...        negative\n",
       "4  @VirginAmerica yes, nearly every time I fly VX...        positive"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10262, 2)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debate_tweets = pd.read_csv('gop_debate_tweets.csv')\n",
    "debate_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text tweet_sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         neutral\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...        positive\n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         neutral\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...        positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...        positive"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debate_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = tweets.drop('directed_at', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets = tweets.append(negative_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10155, 3)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets = all_tweets.drop('X', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10155, 2)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets = all_tweets.append(airline_tweets)\n",
    "all_tweets = all_tweets.append(debate_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31984, 2)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ingest(all_tweets):\n",
    "    all_tweets = all_tweets[all_tweets['tweet_text'].isnull() == False]\n",
    "    all_tweets = all_tweets[all_tweets['tweet_sentiment'].isnull() == False]\n",
    "    return all_tweets\n",
    "\n",
    "all_tweets = ingest(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31983, 2)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15138, 2), (10397, 2), (6448, 2))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets[all_tweets['tweet_sentiment'] == 'negative'].shape, all_tweets[all_tweets['tweet_sentiment'] == 'neutral'].shape, all_tweets[all_tweets['tweet_sentiment'] == 'positive'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_tweets['tweet_text'] = all_tweets['tweet_text'].apply(lambda x: x.lower())\n",
    "#all_tweets['tweet_text'] = all_tweets['tweet_text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','', x)))\n",
    "\n",
    "max_features = 6000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(all_tweets['tweet_text'].values)\n",
    "X = tokenizer.texts_to_sequences(all_tweets['tweet_text'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31983, 50)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    6,   34,    4, 1721,\n",
       "         53,  103,  134,  382,  963,   16, 2639,   84,   23,   32, 1290,\n",
       "          6,   88,    2,  666,   16,    3], dtype=int32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(all_tweets['tweet_sentiment']).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28784, 50), (28784, 3), (3199, 50), (3199, 3))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0, 1542,   35,  173, 2306, 3002, 1570,   45,   31, 3002,   20,\n",
       "        109,    8,  808,  178,    3,   22], dtype=int32)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three models: Simple Neural Network, CNN, and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single hidden layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_dim = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1]))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 50, 32)            192000    \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 50, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 100)               160100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 352,803\n",
      "Trainable params: 352,603\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25905 samples, validate on 2879 samples\n",
      "Epoch 1/30\n",
      "Epoch 00000: val_loss improved from inf to 0.89832, saving model to tweet_sentiment_simple\n",
      "6s - loss: 1.0496 - acc: 0.5126 - val_loss: 0.8983 - val_acc: 0.6110\n",
      "Epoch 2/30\n",
      "Epoch 00001: val_loss improved from 0.89832 to 0.75921, saving model to tweet_sentiment_simple\n",
      "2s - loss: 0.8369 - acc: 0.6306 - val_loss: 0.7592 - val_acc: 0.6509\n",
      "Epoch 3/30\n",
      "Epoch 00002: val_loss improved from 0.75921 to 0.75578, saving model to tweet_sentiment_simple\n",
      "2s - loss: 0.7683 - acc: 0.6545 - val_loss: 0.7558 - val_acc: 0.6415\n",
      "Epoch 4/30\n",
      "Epoch 00003: val_loss improved from 0.75578 to 0.73716, saving model to tweet_sentiment_simple\n",
      "2s - loss: 0.7314 - acc: 0.6659 - val_loss: 0.7372 - val_acc: 0.6520\n",
      "Epoch 5/30\n",
      "Epoch 00004: val_loss did not improve\n",
      "2s - loss: 0.7099 - acc: 0.6745 - val_loss: 0.7404 - val_acc: 0.6534\n",
      "Epoch 6/30\n",
      "Epoch 00005: val_loss did not improve\n",
      "2s - loss: 0.6931 - acc: 0.6817 - val_loss: 0.7594 - val_acc: 0.6478\n",
      "Epoch 7/30\n",
      "Epoch 00006: val_loss did not improve\n",
      "2s - loss: 0.6650 - acc: 0.6937 - val_loss: 0.7630 - val_acc: 0.6540\n",
      "Model took 21.23 seconds to train\n",
      "3199/3199 [==============================] - 1s     \n",
      "[0.71876800293175647, 0.65926852152473514]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint = ModelCheckpoint(filepath='tweet_sentiment_simple', verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, validation_split=0.1, epochs=30, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))\n",
    "\n",
    "# Re-instantiate model to the best model saved\n",
    "model = load_model('tweet_sentiment_simple')\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=64)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single conv layer with max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1], embeddings_regularizer=l2(0.001)))\n",
    "model2.add(SpatialDropout1D(0.55))\n",
    "model2.add(Conv1D(32, 5, padding='same', activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(MaxPool1D())\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(100, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.7))\n",
    "model2.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_35 (Embedding)     (None, 50, 128)           768000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_8 (Spatial (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 50, 32)            20512     \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 50, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 25, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 100)               80100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 869,315\n",
      "Trainable params: 869,115\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25905 samples, validate on 2879 samples\n",
      "Epoch 1/30\n",
      "Epoch 00000: val_loss improved from inf to 1.02878, saving model to tweet_sentiment_cnn\n",
      "17s - loss: 1.1848 - acc: 0.5540 - val_loss: 1.0288 - val_acc: 0.6210\n",
      "Epoch 2/30\n",
      "Epoch 00001: val_loss improved from 1.02878 to 0.88474, saving model to tweet_sentiment_cnn\n",
      "13s - loss: 0.9367 - acc: 0.6456 - val_loss: 0.8847 - val_acc: 0.6554\n",
      "Epoch 3/30\n",
      "Epoch 00002: val_loss improved from 0.88474 to 0.87436, saving model to tweet_sentiment_cnn\n",
      "13s - loss: 0.8777 - acc: 0.6567 - val_loss: 0.8744 - val_acc: 0.6429\n",
      "Epoch 4/30\n",
      "Epoch 00003: val_loss improved from 0.87436 to 0.87097, saving model to tweet_sentiment_cnn\n",
      "13s - loss: 0.8578 - acc: 0.6602 - val_loss: 0.8710 - val_acc: 0.6488\n",
      "Epoch 5/30\n",
      "Epoch 00004: val_loss improved from 0.87097 to 0.87083, saving model to tweet_sentiment_cnn\n",
      "13s - loss: 0.8499 - acc: 0.6645 - val_loss: 0.8708 - val_acc: 0.6575\n",
      "Epoch 6/30\n",
      "Epoch 00005: val_loss did not improve\n",
      "13s - loss: 0.8507 - acc: 0.6640 - val_loss: 0.8798 - val_acc: 0.6408\n",
      "Epoch 7/30\n",
      "Epoch 00006: val_loss did not improve\n",
      "13s - loss: 0.8509 - acc: 0.6699 - val_loss: 0.8897 - val_acc: 0.6527\n",
      "Epoch 8/30\n",
      "Epoch 00007: val_loss did not improve\n",
      "13s - loss: 0.8554 - acc: 0.6703 - val_loss: 0.8924 - val_acc: 0.6523\n",
      "Model took 114.34 seconds to train\n",
      "3040/3199 [===========================>..] - ETA: 0s[0.85872761492954264, 0.65145357937393955]\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint = ModelCheckpoint(filepath='tweet_sentiment_cnn', verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model2.fit(X_train, y_train, batch_size=64, validation_split=0.1, epochs=30, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))\n",
    "\n",
    "# Re-instantiate model to the best model saved\n",
    "model2 = load_model('tweet_sentiment_cnn')\n",
    "\n",
    "y_pred = model2.predict(X_test, batch_size=64)\n",
    "score = model2.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_40 (Embedding)     (None, 50, 64)            384000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_13 (Spatia (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 3)                 291       \n",
      "=================================================================\n",
      "Total params: 446,115\n",
      "Trainable params: 446,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 64\n",
    "lstm_out = 96\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(max_features, embed_dim, input_length = X.shape[1]))\n",
    "model3.add(SpatialDropout1D(0.7))\n",
    "model3.add(LSTM(lstm_out, dropout=0.6, recurrent_dropout=0.6))\n",
    "model3.add(Dense(3, activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25905 samples, validate on 2879 samples\n",
      "Epoch 1/30\n",
      "Epoch 00000: val_loss improved from inf to 0.78014, saving model to tweet_sentiment_lstm\n",
      "56s - loss: 0.8905 - acc: 0.5965 - val_loss: 0.7801 - val_acc: 0.6440\n",
      "Epoch 2/30\n",
      "Epoch 00001: val_loss improved from 0.78014 to 0.74899, saving model to tweet_sentiment_lstm\n",
      "52s - loss: 0.7761 - acc: 0.6488 - val_loss: 0.7490 - val_acc: 0.6499\n",
      "Epoch 3/30\n",
      "Epoch 00002: val_loss improved from 0.74899 to 0.72615, saving model to tweet_sentiment_lstm\n",
      "52s - loss: 0.7368 - acc: 0.6682 - val_loss: 0.7261 - val_acc: 0.6832\n",
      "Epoch 4/30\n",
      "Epoch 00003: val_loss improved from 0.72615 to 0.70754, saving model to tweet_sentiment_lstm\n",
      "51s - loss: 0.7097 - acc: 0.6841 - val_loss: 0.7075 - val_acc: 0.6978\n",
      "Epoch 5/30\n",
      "Epoch 00004: val_loss improved from 0.70754 to 0.68587, saving model to tweet_sentiment_lstm\n",
      "51s - loss: 0.6816 - acc: 0.7014 - val_loss: 0.6859 - val_acc: 0.7082\n",
      "Epoch 6/30\n",
      "Epoch 00005: val_loss improved from 0.68587 to 0.68091, saving model to tweet_sentiment_lstm\n",
      "51s - loss: 0.6594 - acc: 0.7138 - val_loss: 0.6809 - val_acc: 0.7009\n",
      "Epoch 7/30\n",
      "Epoch 00006: val_loss improved from 0.68091 to 0.67958, saving model to tweet_sentiment_lstm\n",
      "51s - loss: 0.6486 - acc: 0.7211 - val_loss: 0.6796 - val_acc: 0.7089\n",
      "Epoch 8/30\n",
      "Epoch 00007: val_loss improved from 0.67958 to 0.67443, saving model to tweet_sentiment_lstm\n",
      "52s - loss: 0.6239 - acc: 0.7358 - val_loss: 0.6744 - val_acc: 0.7086\n",
      "Epoch 9/30\n",
      "Epoch 00008: val_loss improved from 0.67443 to 0.67258, saving model to tweet_sentiment_lstm\n",
      "52s - loss: 0.6138 - acc: 0.7440 - val_loss: 0.6726 - val_acc: 0.7200\n",
      "Epoch 10/30\n",
      "Epoch 00009: val_loss did not improve\n",
      "54s - loss: 0.6005 - acc: 0.7479 - val_loss: 0.6746 - val_acc: 0.7166\n",
      "Epoch 11/30\n",
      "Epoch 00010: val_loss did not improve\n",
      "59s - loss: 0.5876 - acc: 0.7546 - val_loss: 0.6795 - val_acc: 0.7183\n",
      "Epoch 12/30\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint = ModelCheckpoint(filepath='tweet_sentiment_lstm', verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model3.fit(X_train, y_train, batch_size=64, validation_split=0.1, epochs=30, verbose=2, \n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))\n",
    "\n",
    "# Re-instantiate model to the best model saved\n",
    "model3 = load_model('tweet_sentiment_lstm')\n",
    "\n",
    "y_pred = model3.predict(X_test, batch_size=64)\n",
    "score = model3.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
