{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image \n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications import VGG16\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Training Directories for Dogs and Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = %pwd\n",
    "train_path = pwd + '/train/'\n",
    "cats_path = train_path + 'cats/'\n",
    "dogs_path = train_path + 'dogs/'\n",
    "\n",
    "if not os.path.exists(cats_path):\n",
    "    os.makedirs(cats_path)\n",
    "\n",
    "if not os.path.exists(dogs_path):\n",
    "    os.makedirs(dogs_path)\n",
    "    \n",
    "for f in os.listdir(train_path):\n",
    "    if f.endswith('.jpg'):\n",
    "        if f.startswith('cat'):\n",
    "            shutil.move(train_path + f, cats_path + f)\n",
    "        elif f.startswith('dog'):\n",
    "            shutil.move(train_path + f, dogs_path + f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cat files: 12500\n",
      "Number of dog files: 12500\n",
      "Resizing images and loading training set ...\n",
      "... completed.\n"
     ]
    }
   ],
   "source": [
    "cat_files = sorted(glob(cats_path + 'cat*.jpg'))\n",
    "dog_files = sorted(glob(dogs_path + 'dog*.jpg'))\n",
    "\n",
    "print(\"Number of cat files: \" + str(len(cat_files)))\n",
    "print(\"Number of dog files: \" + str(len(dog_files)))\n",
    "\n",
    "n_files = len(cat_files) + len(dog_files)\n",
    "\n",
    "size_image = 64\n",
    "\n",
    "x_train = np.zeros((n_files, size_image, size_image, 3), dtype='float64')\n",
    "y_train = np.zeros(n_files)\n",
    "count = 0\n",
    "\n",
    "print(\"Resizing images and loading training set ...\")\n",
    "\n",
    "for f in cat_files:\n",
    "    img = Image.open(f)\n",
    "    new_img = img.resize((size_image, size_image))\n",
    "    x_train[count] = np.asarray(new_img, dtype='float64')\n",
    "    y_train[count] = 0\n",
    "    count = count + 1\n",
    "\n",
    "for f in dog_files:\n",
    "    img = Image.open(f)\n",
    "    new_img = img.resize((size_image, size_image))\n",
    "    x_train[count] = np.asarray(new_img, dtype='float64')\n",
    "    y_train[count] = 1\n",
    "    count = count + 1\n",
    "\n",
    "print(\"... completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle cats and dogs, and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permutation: [18781   864  5298 ...,  8046 17069  1997]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "permutation = np.random.permutation(x_train.shape[0])\n",
    "print(\"permutation: \" + str(permutation))\n",
    "\n",
    "x_train = x_train[permutation]\n",
    "y_train = y_train[permutation]\n",
    "\n",
    "x_train = x_train / 255.\n",
    "y_train = utils.to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAgfElEQVR4nIV66Y9lx3VfrXe/9+3v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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1B8715710>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.uint8(x_train[10001] * 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[10001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Model**\n",
    "\n",
    "This model resulted in good 83-85% validation and test accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 2,224,962\n",
      "Trainable params: 2,208,066\n",
      "Non-trainable params: 16,896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 30\n",
    "\n",
    "X_train = x_train[:22500]\n",
    "Y_train = y_train[:22500]\n",
    "X_valid = x_train[22500:23750]\n",
    "Y_valid = y_train[22500:23750]\n",
    "X_test = x_train[23750:25000]\n",
    "Y_test = y_train[23750:25000]\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint = ModelCheckpoint(filepath='dogs_v_cats', verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train, Y_train, validation_data=[X_valid, Y_valid], callbacks=[model_checkpoint, early_stopping], \n",
    "          epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))\n",
    "\n",
    "# Re-instantiate model to the best model saved\n",
    "model = models.load_model('dogs_v_cats')\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:07<00:00, 183.97it/s]\n"
     ]
    }
   ],
   "source": [
    "test_path = pwd + '/test/'\n",
    "\n",
    "testing_data = []\n",
    "for image in tqdm(os.listdir(test_path)):\n",
    "    path = os.path.join(test_path, image)\n",
    "    img_num = image.split('.')[0]\n",
    "    img = Image.open(path)\n",
    "    new_img = img.resize((size_image, size_image))\n",
    "    testing_data.append([np.asarray(new_img, dtype='float64'), img_num])\n",
    "\n",
    "#    np.save('test_data.npy', testing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission-file.csv', 'w') as f:\n",
    "    f.write('id,label\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:38<00:00, 320.91it/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.load_model('dogs_v_cats')\n",
    "\n",
    "with open('submission-file.csv', 'a') as f:\n",
    "    for data in tqdm(testing_data):\n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(1, size_image, size_image, 3)\n",
    "        model_out = np.clip(model.predict([data])[0], 0.05, 0.95) #np.clip is used to keep the range of predictions between 0.05 and 0.95\n",
    "        \n",
    "        f.write('{},{}\\n'.format(img_num, model_out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Conv2D(64, (3,3), activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(BatchNormalization())\n",
    "\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Epoch 00000: val_loss improved from inf to 0.69699, saving model to dogs_v_cats\n",
      "154s - loss: 0.8001 - acc: 0.5623 - val_loss: 0.6970 - val_acc: 0.5152\n",
      "Epoch 2/30\n",
      "Epoch 00001: val_loss did not improve\n",
      "157s - loss: 0.6511 - acc: 0.6155 - val_loss: 0.7234 - val_acc: 0.4848\n",
      "Epoch 3/30\n",
      "Epoch 00002: val_loss did not improve\n",
      "157s - loss: 0.6368 - acc: 0.6295 - val_loss: 0.8847 - val_acc: 0.5152\n",
      "Epoch 4/30\n",
      "Epoch 00003: val_loss did not improve\n",
      "159s - loss: 0.6166 - acc: 0.6556 - val_loss: 0.9373 - val_acc: 0.5152\n",
      "Model took 629.31 seconds to train\n",
      "[0.71098765544891362, 0.47760000000000002]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 30\n",
    "\n",
    "X_train = x_train[:22500]\n",
    "Y_train = y_train[:22500]\n",
    "X_valid = x_train[22500:23750]\n",
    "Y_valid = y_train[22500:23750]\n",
    "X_test = x_train[23750:25000]\n",
    "Y_test = y_train[23750:25000]\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint = ModelCheckpoint(filepath='dogs_v_cats_dataaug', verbose=1, save_best_only=True)\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             zoom_range=0.25,\n",
    "                             horizontal_flip=True)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "steps = len(X_train) / batch_size\n",
    "start = time.time()\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model2.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=steps, epochs=epochs, \n",
    "                    validation_data=[X_valid, Y_valid], callbacks=[model_checkpoint, early_stopping],\n",
    "                    verbose=2)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Model took %0.2f seconds to train\"%(end - start))\n",
    "\n",
    "# Re-instantiate model to the best model saved\n",
    "model2 = models.load_model('dogs_v_cats_dataaug')\n",
    "\n",
    "y_pred = model2.predict(X_test, batch_size=batch_size)\n",
    "score = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
